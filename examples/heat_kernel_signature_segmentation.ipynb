{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh Segmentation using Heat Kernel Signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Setup for Mesh Segmentation using Heat Kernel Signature (HKS)\n",
    "# This cell initialises the necessary libraries.\n",
    "# ============================================================\n",
    "__author__ = \"Faisal Jayousi\"\n",
    "\n",
    "from pathlib import Path  # For handling file paths\n",
    "\n",
    "import matplotlib.pyplot as plt  # For plotting visualizations\n",
    "import meshplot as mp  # For 3D mesh visualization\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as skp\n",
    "\n",
    "from geotopomethods import SegmentMesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def off2numpy(shape_name):\n",
    "    \"\"\"\n",
    "    Converts a .off file to NumPy arrays representing vertices and faces.\n",
    "\n",
    "    Parameters:\n",
    "        shape_name (str): Path to the .off file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (vertices, faces) where:\n",
    "            - vertices (np.ndarray): Array of vertex coordinates.\n",
    "            - faces (np.ndarray): Array of face indices.\n",
    "    \"\"\"\n",
    "    with open(shape_name, \"r\") as file:\n",
    "        # Skip the first line and read number of vertices and faces\n",
    "        file.readline()\n",
    "        num_vertices, num_faces, _ = map(int, file.readline().split())\n",
    "\n",
    "        # Read the remaining lines\n",
    "        data = file.readlines()\n",
    "\n",
    "    # Parse vertices and faces\n",
    "    vertices = np.array(\n",
    "        [list(map(float, line.split())) for line in data[:num_vertices]]\n",
    "    )\n",
    "    faces = np.array(\n",
    "        [list(map(int, line.split()[1:])) for line in data[num_vertices:]]\n",
    "    )\n",
    "\n",
    "    return vertices, faces\n",
    "\n",
    "\n",
    "def get_labels(label_name, num_faces):\n",
    "    \"\"\"\n",
    "    Reads label information and associates labels with mesh faces.\n",
    "\n",
    "    Parameters:\n",
    "        label_name (str): Path to the label file.\n",
    "        num_faces (int): Number of faces in the mesh.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of labels for each face.\n",
    "    \"\"\"\n",
    "    labels_array = np.empty([num_faces], dtype=\"|S100\")\n",
    "\n",
    "    with open(label_name, \"r\") as S:\n",
    "        info = S.readlines()\n",
    "\n",
    "    labels, face_indices = info[0::2], info[1::2]\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        indices = [int(f) - 1 for f in face_indices[i].split(\" \")[:-1]]\n",
    "        labels_array[np.array(indices)] = lab[:-1]\n",
    "    return labels_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Visualising Mesh Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"..\" / Path('data')\n",
    "vertices, faces = off2numpy(dataset_path / 'Human' / '20.off')\n",
    "label_faces = get_labels(dataset_path / 'Human' / '20_labels.txt', len(faces))\n",
    "\n",
    "mp.plot(vertices, faces, c=skp.LabelEncoder().fit_transform(label_faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hks(t, eigenvalues: np.ndarray, eigenvectors: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute Heat Kernal Signature (HKS) for a given t.\n",
    "\n",
    "    Args:\n",
    "        t : float\n",
    "            Time scale parameter.\n",
    "        eigenvalues : np.ndarray\n",
    "            1D array of eigenvalues obtained from the Laplacian\n",
    "        eigenvectors : np.ndarray\n",
    "            2D array of eigenvectors. Shape: (n_points, n_eigenvalues)\n",
    "    \"\"\"\n",
    "    exp_decay = np.exp(-eigenvalues * t)  # Shape (n_eigenvalues,)\n",
    "    hks_values = np.sum(exp_decay[None, :] * np.square(eigenvectors), axis=1)\n",
    "    return hks_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhs = SegmentMesh(vertices, faces)\n",
    "mhs.compute_laplacian(k=200)\n",
    "mhs.build_neighbourhood_graph()\n",
    "\n",
    "weights = hks(0.1, mhs.eigenvalues, mhs.eigenvectors)\n",
    "tomato = mhs(weights=weights)\n",
    "\n",
    "tomato.plot_diagram()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomato.n_clusters_ = 5\n",
    "mp.plot(vertices, faces, c=tomato.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_TOPO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
